# Ansible configuration

## Prerequisites for Running Ansible on Remote Kubernetes Nodes
### Goal
Allow your Ansible control node to execute playbooks on remote Ubuntu machines **via SSH** using a user with **passwordless sudo** access.

<br><br>

## Step-by-Step Instructions
### 1. Generate an SSH Key (on your Ansible control node)
```bash
ssh-keygen -t rsa -b 4096 -C "ansible@control-node"
```

- Press **Enter** to accept default file path (`~/.ssh/id_rsa`)
- Leave passphrase empty for passwordless SSH (optional but convenient)

<br><br>

### 2. Copy Public Key to Remote Nodes
```bash
for host in 192.178.1.100 192.178.1.101 192.178.1.102 192.178.1.103; do
  ssh-copy-id ansible@$host
done
```

> Repeat for each remote machine (`ansible` should be an existing user or one you create in the next step)

<br><br>

### 3. Create an `ansible` User with Sudo (on each remote machine)
If you havenâ€™t already, SSH into each node and create the user:

```bash
sudo adduser ansible
sudo usermod -aG sudo ansible
```

Then allow passwordless sudo:

```bash
echo "ansible ALL=(ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/ansible
sudo chmod 0440 /etc/sudoers.d/ansible
```

<br><br>

### 4. Prepare the Inventory File (on control node)
Create a file called `hosts.ini`:

```ini
[kube_nodes]
c1-cp1 ansible_host=192.178.1.100
c1-node1 ansible_host=192.178.1.101
c1-node2 ansible_host=192.178.1.102
c1-node3 ansible_host=192.178.1.103

[kube_nodes:vars]
ansible_user=ansible
ansible_ssh_private_key_file=~/.ssh/id_rsa
ansible_become=true
ansible_become_method=sudo
```

<br><br>

### 5. Test SSH Connectivity
```bash
ansible -i hosts.ini kube_nodes -m ping
```

You should see all nodes respond with:

```json
c1-cp1 | SUCCESS => {... "ping": "pong" }
```

<br><br>

### 6. Run Your Playbook
```bash
ansible-playbook -i hosts.ini k8s-setup.yml
```
