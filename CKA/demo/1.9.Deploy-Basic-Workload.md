# Demo:<br>Deploying a Basic Workload in Your Cluster
### Step 1: Verify All Nodes Are Ready
Check the status of the control plane and all worker nodes:
```bash
kubectl get nodes
```

### Step 2: Create a Deployment
Deploy a containerized web app using a Deployment with 3 replicas:
```bash
kubectl create deployment hello-world \
  --image=<azure-registry>/hello-app:1.0 \
  --replicas=3
```
> Replace `<azure-registry>` with your actual Azure Container Registry path.
Check the pods and their node assignments:
```bash
kubectl get pods -o wide
```
You should see each pod scheduled on a different worker node (`c1-node1`, `c1-node2`, and `c1-node3`).

<br>

### Step 3: Expose the Deployment as a Service
Expose the deployment internally using a ClusterIP service:
```bash
kubectl expose deployment hello-world \
  --port=80 \
  --target-port=8080
```
Check the service details:
```bash
kubectl get service
```

<br>

### Step 4: Store ClusterIP in an Environment Variable
Save the internal service IP for repeated use:
```bash
SERVICEIP=$(kubectl get service hello-world \
  -o=jsonpath='{.spec.clusterIP}')
```
Check:
```bash
echo $SERVICEIP
```

<br>

### Step 5: Access the App Using curl
Curl the service IP (from within a pod or node that can access ClusterIP):
```bash
curl $SERVICEIP
```
You should see a response like:
```
hello-world v1.0 from pod <pod-name>
```
Each curl hit should randomly show a different pod name due to round-robin load balancing.

<br>

### Step 6: Clean Up
Delete the resources when done:
```bash
kubectl delete deployment hello-world
kubectl delete service hello-world
```
